# üìå Relat√≥rio de Experimenta√ß√£o em Aprendizagem de M√°quina (Titanic)

## 1. Objetivo do Trabalho e Identifica√ß√£o

O projeto tem como objetivo principal aplicar um fluxo completo de Data Science (EDA, Pr√©-processamento e Modelagem) para resolver um problema de Classifica√ß√£o Bin√°ria. Utilizamos o dataset do Titanic para investigar e prever as chances de sobreviv√™ncia de passageiros com base em caracter√≠sticas demogr√°ficas e de viagem. O modelo de √Årvore de Decis√£o foi selecionado pela sua alta interpretabilidade e facilidade de aplica√ß√£o.  

---

## üë• Integrantes

- Andr√© Henrique da Silva ‚Äî RA: 851001  
- Jo√£o Gustavo Pires Da Costa ‚Äî RA: 2419919 
- Leonardo Elias Figueiredo ‚Äî RA: 856987
- Luiz Gustavo Julio Salles - RA: 1449850
- Vinicius Azevedo de √Åvila  ‚Äî RA: 1048328

---

## 2. üîó Dataset Utilizado

- **NOME DO DATASET:** Titanic - Machine Learning from Disaster  
- **LINK (KAGGLE):** https://www.kaggle.com/c/titanic  
- **DESCRI√á√ÉO DO DATASET:** 891 amostras (passageiros) e 12 vari√°veis (colunas), incluindo informa√ß√µes como idade, sexo, classe de bilhete, tarifa e porto de embarque. O problema √© de Classifica√ß√£o Bin√°ria.  
- **VARI√ÅVEL-ALVO (TARGET):** Survived (Sobreviv√™ncia: 1 para Sim, 0 para N√£o).  
- **JUSTIFICATIVA DA ESCOLHA:** O dataset √© ideal para iniciantes em Machine Learning, pois possui uma estrutura clara, vari√°veis f√°ceis de interpretar e permite o uso de um modelo simples como a √Årvore de Decis√£o sem exigir t√©cnicas complexas de pr√©-processamento. 

---

## 3. üß† Modelo de Aprendizagem de M√°quina

**√Årvore de Decis√£o**  

 A √Årvore de Decis√£o √© um modelo de aprendizado supervisionado utilizado tanto para **regress√£o** quanto para **classifica√ß√£o**. Neste projeto, ele √© usado para **classificar** se um **passageiro sobreviveu ou n√£o.** 

 Foi escolhido por sua ***simplicidade** e **interpretabilidade.** O modelo n√£o exige padroniza√ß√£o de vari√°veis e permite visualizar a hierarquia das decis√µes, facilitando a compreens√£o de quais features (vari√°veis) s√£o mais importantes na previs√£o.

 O modelo cria uma estrutura de fluxograma. Ele divide o conjunto de dados sequencialmente em n√≥s (**decis√µes**) baseados na feature que melhor separa as classes (**Survived=1 e Survived=0**). O processo continua at√© que os grupos fiquem o mais "puros" poss√≠vel, resultando em "folhas" que cont√™m a **previs√£o final.**

---

## 4. üìä An√°lise Explorat√≥ria dos Dados (EDA)

### 4.1 Estat√≠sticas Descritivas e Qualidade dos Dados

**Estat√≠sticas Descritivas:** A taxa de sobreviv√™ncia m√©dia foi de **38%** , indicando que o desequil√≠brio de classes √© moderado. A idade m√©dia dos passageiros era de aproximadamente **29.7 anos.**

**Valores Ausentes:** As colunas **Cabin** (muitos nulos), **Age** e **Embarked** apresentaram valores faltantes, que foram **tratados.**


### 4.2 Visualiza√ß√£o dos Dados e Padr√µes Relevantes

**Sexo:** A sobreviv√™ncia foi drasticamente maior para o g√™nero **feminino.** Este √© o fator de **maior peso na previs√£o.**
![Gr√°fico de Sobreviv√™ncia por G√™nero](docs/GRAFICO_SOBREVIVENCIA_GENERO.png)

**Classe da Passagem (Pclass):** Passageiros da 1¬™ classe tiveram a maior taxa de **sobreviv√™ncia**, enquanto a 3¬™ classe teve a menor. Isso indica uma correla√ß√£o clara entre status socioecon√¥mico e resgate.
![Gr√°fico de Sobreviv√™ncia por Classe](docs/GRAFICO_CLASSE_PASSAGEM.png)

---
## 5. Prepara√ß√£o dos Dados

### 5.1 Tratamento de Dados Ausentes
**Age:** Preenchida com a mediana (**28.0**) para manter a distribui√ß√£o.

**Embarked:** Preenchida com a moda (**Porto 'S'**) devido √† pequena quantidade de nulos.

### 5.2 Codifica√ß√£o de Vari√°veis Categ√≥ricas
**Codifica√ß√£o:** As vari√°veis categ√≥ricas (**Sex, Embarked, Pclass**) foram convertidas em formato num√©rico utilizando One-Hot Encoding **(pd.get_dummies**), criando colunas bin√°rias (**Ex: Sex_male, Pclass_2**).

### 5.3 Padroniza√ß√£o ou Normaliza√ß√£o

**Padroniza√ß√£o (StandardScaler):** **N√£o** foi necess√°ria a aplica√ß√£o de **Padroniza√ß√£o**, pois o modelo escolhido (**√Årvore de Decis√£o**) √© baseado em **regras** e **divis√µes** e n√£o em **dist√¢ncias**, sendo insens√≠vel √† escala das features.

## 6. üß™ Treinamento e Testes do Modelo
### Divis√£o dos Dados
Os dados foram divididos em conjuntos de Treino (**80%**) e Teste (**20%**) usando train_test_split(random_state=42).

O c√≥digo completo do projeto, incluindo EDA, Pr√©-processamento, Treinamento e M√©tricas, est√° dispon√≠vel no notebook.
Link para o notebook no Google Colab (Visualiza√ß√£o): [https://colab.research.google.com/drive/1LL3bvcBt-LP3CKVsDM64p1XDHyH2Jy95?usp=sharing]

---

## 7. üìê M√©tricas de Avalia√ß√£o

Como o projeto utiliza um modelo de **Classifica√ß√£o Bin√°ria** (prever se o passageiro sobreviveu ou n√£o), utilizamos as seguintes m√©tricas para medir o desempenho do modelo no conjunto de teste:

### **Para Classifica√ß√£o**

**1. Accuracy (Acur√°cia)**

**O que √©:** √â a medida mais simples. Representa a propor√ß√£o de todas as previs√µes que o modelo acertou (acertos totais dividido pelo n√∫mero total de amostras).

 **Resultado:** O modelo final (√Årvore de Profundidade=3) alcan√ßou **79.89%** de **Acur√°cia.**

**2. Matriz de Confus√£o**

**O que √©:** √â uma tabela que mostra exatamente onde o modelo acertou e errou em cada classe. Ajuda a diferenciar os tipos de erros.

**Componentes e Explica√ß√£o Intuitiva:**

True Positive (TP): O modelo disse que Sobreviveu, e estava Certo. (Acerto de sobreviventes)

True Negative (TN): O modelo disse que N√£o Sobreviveu, e estava Certo. (Acerto de n√£o sobreviventes)

False Positive (FP): O modelo disse que Sobreviveu, mas o passageiro N√£o Sobreviveu. (Erro Tipo I: Falso Alarme)

False Negative (FN): O modelo disse que N√£o Sobreviveu, mas o passageiro Sobreviveu. (Erro Tipo II: Falha em detectar)

 **Resultado** (Exemplo do Exp. 1): O modelo acertou **81 previs√µes** de **n√£o-sobreviv√™ncia** (TN) e **54 de sobreviv√™ncia** (TP).

**3. Precision (Precis√£o)**

**O que √©:** Responde √† pergunta: "Das vezes que o modelo previu 'Sobreviveu', quantas ele acertou de verdade?"

**Explica√ß√£o Simples:** √â importante quando voc√™ quer minimizar o Falso Positivo (FP). No contexto de um resgate, voc√™ quer que as pessoas que voc√™ aponta como sobreviventes realmente sejam sobreviventes.

 **Resultado** (Exp. 1): **71.05%**

**4. Recall (Sensibilidade)**

**O que √©:** Responde √† pergunta: "Dos passageiros que realmente sobreviveram, quantos o modelo conseguiu identificar corretamente?"

**Explica√ß√£o Simples:** √â importante quando voc√™ quer minimizar o Falso Negativo (FN). No contexto m√©dico ou de seguran√ßa, voc√™ n√£o quer deixar de detectar um caso positivo.

 **Resultado** (Exp. 1): **72.97%**

**Sobre Regress√£o:** As m√©tricas de Regress√£o (**MAE, RMSE, R¬≤**) **n√£o** foram utilizadas neste projeto, pois o **problema** do Titanic √© de **Classifica√ß√£o** (prever uma categoria: 0 ou 1). Essas m√©tricas seriam aplic√°veis se **estiv√©ssemos prevendo um valor cont√≠nuo**, como a tarifa paga pelo passageiro.

---

## 8. üß¨ Experimentos Realizados

O grupo realizou tr√™s experimentos com a **√Årvore de Decis√£o** (Decision Tree) para otimizar a performance, combater o **Overfitting** e avaliar a relev√¢ncia das vari√°veis.

**Experimento 1: Modelo Baseline (√Årvore de Profundidade Ilimitada)**

Este experimento estabeleceu a linha de base para compara√ß√£o. O modelo foi treinado sem nenhuma restri√ß√£o de complexidade (**max_depth=None, o padr√£o do Scikit-learn**).

**M√©trica**	                    **Resultado**
Accuracy (Acur√°cia)	               76.54%

**C√≥digo e Interpreta√ß√£o**

![C√≥digo do Experimento 1 - Baseline](docs/Exp_1.png)

**Interpreta√ß√£o:** Embora a acur√°cia seja aceit√°vel, o resultado √© comparativamente baixo para um modelo irrestrito, o que levantou a suspeita de **Overfitting** (o modelo memorizou os dados de treino e **falhou** em generalizar para os dados de teste).

**Experimento 2: Limita√ß√£o da Profundidade da √Årvore**

O objetivo foi combater o Overfitting restringindo a complexidade do modelo. Limitamos a profundidade m√°xima da √°rvore para max_depth=3.

**M√©trica**	                    **Resultado**
Accuracy (Acur√°cia)                79.89% 

**C√≥digo e Interpreta√ß√£o**

![C√≥digo do Experimento 2 - Profundidade 3](docs/Exp_2.png)

**Interpreta√ß√£o:** A acur√°cia melhorou de **76.54%** para **79.89%.** Este ganho significativo confirma que o **Experimento 1** estava sobreajustado. Limitar o max_depth for√ßou a √°rvore a focar apenas nas features mais importantes (**Sexo, Classe**), resultando em um modelo mais robusto e com melhor capacidade de generaliza√ß√£o.

**Experimento 3: Remo√ß√£o da Vari√°vel Parch (Sele√ß√£o de Features)**

Testamos se a remo√ß√£o da vari√°vel Parch (**N√∫mero de Pais/Filhos a bordo**), que se mostrou pouco correlacionada na EDA, afetaria o desempenho do nosso melhor modelo (**max_depth=3**).

**M√©trica**	                    **Resultado**
Accuracy (Acur√°cia)                79.89% 

**C√≥digo e Interpreta√ß√£o**

![C√≥digo do Experimento 3 - Sem Parch](docs/Exp_3.png)

**Interpreta√ß√£o:** A acur√°cia permaneceu **inalterada.** Conclu√≠mos que a vari√°vel **Parch** n√£o adiciona poder preditivo ao modelo. Dessa forma, podemos **remov√™-la** do modelo final sem perda de **performance**, tornando a solu√ß√£o mais **simples e limpa.**


---

## 9. üìà Resultados e An√°lise

Esta se√ß√£o resume o desempenho do modelo de **√Årvore de Decis√£o** ap√≥s a otimiza√ß√£o dos **hiperpar√¢metros.**

**1. Desempenho do Modelo e An√°lise de Overfitting**
O modelo foi avaliado nos tr√™s experimentos realizados:

**Experimento 1 (Modelo Baseline):** Obteve **76.54%** de Acur√°cia no teste. O resultado foi considerado um indicativo de **Overfitting** (sobreajuste), pois o modelo sem restri√ß√£o de complexidade se ajustou demais aos dados de treino.

**Experimento 2 (Otimizado):** O modelo restrito com max_depth=3 alcan√ßou **79.89%** de Acur√°cia. Este aumento significativo (mais de 3 pontos percentuais) confirma que a otimiza√ß√£o do hiperpar√¢metro corrigiu o Overfitting e produziu o **modelo mais robusto.**

**Experimento 3 (Simplificado):** A remo√ß√£o da vari√°vel Parch (Pais/Filhos) n√£o alterou a performance, mantendo a Acur√°cia em **79.89%.**

**Como o modelo se comportou?** O modelo final (Experimento 2) demonstrou um comportamento robusto e est√°vel, atingindo uma Acur√°cia de **79.89%** no conjunto de teste. O desempenho √© forte para um modelo de Machine Learning com alta interpretabilidade.

**2. Vari√°veis de Maior Influ√™ncia**
Quais vari√°veis t√™m maior influ√™ncia? A estrutura da √Årvore de Decis√£o confirmou os achados da EDA, mostrando que as vari√°veis cruciais na previs√£o s√£o:

**Sexo:** O fator mais importante, sendo a primeira divis√£o da √°rvore.

**Classe da Passagem (Pclass):** A segunda vari√°vel mais influente no resultado da sobreviv√™ncia.

A vari√°vel Parch foi descartada, pois o Experimento 3 comprovou que ela tem pouca ou nenhuma relev√¢ncia preditiva.

**3. M√©tricas Detalhadas do Modelo Final**
Para o modelo final otimizado (Experimento 2), as m√©tricas detalhadas s√£o:

**Acur√°cia Geral:** 79.89%

**Precision (Sobreviveu):** 71% (Aproximadamente)

**Recall (Sobreviveu):** 73% (Aproximadamente)

**Matriz de Confus√£o**

![Matriz de Confus√£o do Modelo](docs/GRAFICO_MATRIZ_CONF.png)

A Matriz de Confus√£o confirma que o modelo foi **eficiente** tanto em **identificar** quem **n√£o sobreviveu** (True Negatives) quanto em identificar **quem sobreviveu** (True Positives), sem um **vi√©s excessivo.**

**4. Validade do Modelo**
O modelo faz sentido para esse conjunto de dados? **Sim.** O modelo de **√Årvore de Decis√£o** √© **extremamente adequado**, pois suas decis√µes e a import√¢ncia de suas vari√°veis (**Sexo e Classe**) est√£o diretamente alinhadas com o contexto hist√≥rico e social do desastre do Titanic. O modelo n√£o apenas prev√™, mas tamb√©m explica os principais fatores de **sobreviv√™ncia.**

---

## 10. üß© Conclus√µes Finais

A execu√ß√£o deste projeto demonstrou um fluxo completo de Data Science, desde a an√°lise explorat√≥ria at√© a otimiza√ß√£o do modelo, culminando em uma solu√ß√£o robusta e interpret√°vel para o problema de Classifica√ß√£o.

**1. O que aprenderam sobre o modelo escolhido (√Årvore de Decis√£o)?**

**Interpretabilidade e Simplicidade:** A √Årvore de Decis√£o provou ser um modelo excelente para iniciantes, pois sua l√≥gica √© transparente e pode ser facilmente visualizada como um fluxograma.

**Controle de Complexidade:** O aprendizado mais crucial foi a import√¢ncia da otimiza√ß√£o de hiperpar√¢metros. O **Experimento 2** demonstrou que limitar a complexidade do modelo (max_depth=3) foi essencial para evitar o Overfitting e melhorar a capacidade do modelo de **generalizar** para dados in√©ditos (**Acur√°cia de 79.89%**).

**2. O que descobriu sobre o conjunto de dados (Titanic)?**

**Fatores Determinantes:** A An√°lise Explorat√≥ria dos Dados (EDA) e a import√¢ncia de features do modelo confirmaram que o fator de maior peso na sobreviv√™ncia foi o **Sexo**, seguido pela **Classe da Passagem (Pclass)**. Isso valida o contexto hist√≥rico de prioridade no resgate.

**Qualidade dos Dados:** O projeto destacou a necessidade de tratamento de dados ausentes, especialmente em Age (preenchida com a mediana), e a irrelev√¢ncia de vari√°veis como Parch, que puderam ser removidas sem preju√≠zo √† performance (Experimento 3).

**3. O que poderia ser feito para melhorar o modelo?**

**Engenharia de Features:** Uma melhoria futura seria a cria√ß√£o de features mais sofisticadas, como uma vari√°vel que agregue o tamanho total da fam√≠lia (**SibSp + Parch**) ou a extra√ß√£o de t√≠tulos (**Mr., Mrs., Master**) da coluna Name para identificar grupos demogr√°ficos com maior precis√£o.

**Compara√ß√£o de Modelos:** Para buscar uma acur√°cia mais alta, poder√≠amos testar modelos de ensemble (**que usam m√∫ltiplas √°rvores**), como o **Random Forest** ou o **Gradient Boosting**, embora isso resultasse em perda de **interpretabilidade.**

**4. O modelo √© adequado para esse tipo de dado?**

**Sim, o modelo de √Årvore de Decis√£o √© altamente adequado.** Ele ofereceu o equil√≠brio ideal entre **performance** (quase **80%** de **acur√°cia**) e **interpretabilidade**. O modelo n√£o apenas previu com sucesso a sobreviv√™ncia, mas tamb√©m forneceu uma explica√ß√£o clara, baseada nos dados, sobre as vari√°veis mais influentes no desastre.  

---

## üìÅ Organiza√ß√£o do Reposit√≥rio

```
O projeto segue a seguinte estrutura de pastas :

üì¶ projeto-datascience/
 ‚î£ üìÇ src/
 ‚îÉ ‚îó model.ipynb           
 ‚î£ üìÇ docs/
 ‚îÉ ‚îó imagens-graficos/
 ‚î£ README.md               
```

## üìù Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa **MIT**.
